import logging
import os.path
import random
import sys
import pickle
import time

import numpy as np
import psola
import soundfile as sf
import sounddevice as sd
import librosa
from PySide6.QtWidgets import (
    QApplication, QWidget, QVBoxLayout, QHBoxLayout,
    QPushButton, QLabel, QFileDialog, QGroupBox, QRadioButton, QComboBox, QDialog
)
from PySide6.QtCore import Qt, QUrl, QTimer, Qt, QThread, Signal, QSize, QCoreApplication

app_name = "AutoTune"
logger = logging.getLogger(app_name)
logger.setLevel(logging.DEBUG)
file_handler = logging.FileHandler(
    mode="w",
    filename=app_name + ".log",
    encoding="utf8",
)
fmt = logging.Formatter(
    fmt="%(asctime)s - %(levelname)s - %(message)s"
)
file_handler.setLevel(logging.INFO)
stream_handler = logging.StreamHandler(stream=sys.stdout)
stream_handler.setLevel(logging.DEBUG)
stream_handler.setFormatter(fmt=fmt)
file_handler.setFormatter(fmt=fmt)
logger.addHandler(file_handler)
logger.addHandler(stream_handler)


def get_key_frequencies(key) -> list:
    """
    æ ¹æ®è°ƒå·è·å–å¯¹åº”çš„éŸ³é˜¶é¢‘ç‡

    å‚æ•°:
    key: è°ƒå·ï¼Œä¾‹å¦‚:C:maj, C#:maj, F:min ç­‰

    è¿”å›:
    åŒ…å«è¯¥è°ƒå·å¯¹åº”çš„æ‰€æœ‰éŸ³é˜¶é¢‘ç‡çš„åˆ—è¡¨
    """
    # å®šä¹‰åŸºæœ¬éŸ³é˜¶é¢‘ç‡ (A4 = 440Hz)
    base_note_freq = 440
    scale_steps = librosa.key_to_degrees(key)
    # è®¡ç®—å¤šä¸ªå…«åº¦çš„éŸ³é˜¶é¢‘ç‡
    frequencies = []

    for octave in range(1, 6):  # è€ƒè™‘å¤šä¸ªå…«åº¦
        for step in scale_steps:
            # è®¡ç®—å½“å‰éŸ³ç¬¦çš„MIDIç¼–å·
            midi_number = 12 * (octave + 1) + step
            # å°†MIDIç¼–å·è½¬æ¢ä¸ºé¢‘ç‡
            frequency = base_note_freq * 2 ** ((midi_number - 69) / 12)
            frequencies.append(frequency)
    frequencies.sort()
    logger.info(f"{key}è°ƒçš„é¢‘ç‡ï¼š\n{frequencies}")
    return frequencies


class Autotune():

    def __init__(self, input_audio_vocal, input_beat, key, flush=False):
        self.input_audio_vocal = input_audio_vocal
        self.input_beat = input_beat  # ä¼´å¥
        self.key = key
        self.fs_vocal = None  # é‡‡æ ·ç‡,vocal
        self.fs_beat = None
        self.y_vocal = None  # vocal info
        self.y_beat = None
        self.pickle_path_shifted_vocal = "vocal_shifted.pickle"
        self.y_vocal_shifted = None  # å¤„ç†ä¹‹åçš„äººå£°
        self.frame_length = 1024  # å¸§é•¿åº¦
        self.fmin = librosa.note_to_hz("C2")
        self.fmax = librosa.note_to_hz("C7")
        # å®šä¹‰åŸºæœ¬éŸ³é˜¶é¢‘ç‡ (A4 = 440Hz)
        # self.base_note_freq = 440
        self.flush = flush
        self.autotune_flag = False  # autotune å¼€å…³
        self.save_ans = False

    def read_audio(self, sound_type=None):
        """
        :param sound_type: Vocal, beat
        :return:
        """

        pickle_path_vocal = "vocal_info.pickle"
        pickle_path_beat = "beat_info.pickle"

        if sound_type == "Vocal" and sound_type:
            logger.info("è¯»å–vocal")
            if self.flush or not os.path.exists(pickle_path_vocal):
                y, fs = sf.read(self.input_audio_vocal)  # y: éŸ³é¢‘æ•°æ® (numpy array)ï¼Œ fs: é‡‡æ ·ç‡
                logger.info(f"audio length: {len(y)}")
                logger.info(f"vocalåŸå§‹é‡‡æ ·ç‡: {fs} Hz")
                # 2. å°†æ—¶åŸŸä¿¡å·å˜ä¸º librosa æ ¼å¼ï¼ˆæµ®ç‚¹æ•°ã€å•å£°é“ï¼‰
                if y.ndim > 1:
                    y = np.mean(y, axis=1)  # è½¬ä¸ºå•å£°é“
                y = y.astype(np.float32)
                self.fs_vocal, self.y_vocal = fs, y
                if sound_type is None:
                    logger.info(f" åºåˆ—åŒ–vocalä¿¡æ¯ ")
                    with open(pickle_path_vocal, mode="wb") as f:
                        pickle.dump((self.fs_vocal, self.y_vocal), f)
            else:
                logger.info(f"ååºåˆ—åŒ–vocalä¿¡æ¯ ")
                with open(pickle_path_vocal, mode="rb") as f:
                    self.fs_vocal, self.y_vocal = pickle.load(f)

        if sound_type == "Beat" and sound_type:
            logger.info("è¯»å–beat")
            if self.flush or not os.path.exists(pickle_path_beat):
                y, fs = sf.read(self.input_beat)  # y: éŸ³é¢‘æ•°æ® (numpy array)ï¼Œ fs: é‡‡æ ·ç‡
                logger.info(f"audio length: {len(y)}")
                logger.info(f"beatåŸå§‹é‡‡æ ·ç‡: {fs} Hz")
                # 2. å°†æ—¶åŸŸä¿¡å·å˜ä¸º librosa æ ¼å¼ï¼ˆæµ®ç‚¹æ•°ã€å•å£°é“ï¼‰
                if y.ndim > 1:
                    y = np.mean(y, axis=1)  # è½¬ä¸ºå•å£°é“
                y = y.astype(np.float32)
                self.fs_beat, self.y_beat = fs, y
                if sound_type is None:
                    logger.info(f" åºåˆ—åŒ–beatä¿¡æ¯ ")
                    with open(pickle_path_beat, mode="wb") as f:
                        pickle.dump((self.fs_beat, self.y_beat), f)
            else:
                logger.info(f"ååºåˆ—åŒ–beatä¿¡æ¯ ")
                with open(pickle_path_beat, mode="rb") as f:
                    self.fs_beat, self.y_beat = pickle.load(f)
    @staticmethod
    def __play_audio_one(y, fs):
        logger.info("start to play one")
        if y is not None:
            logger.info("start to play one yes")
            sd.play(y, fs)

    def stop_play(self):
        logger.info("stop play")
        sd.stop()

    def play_one_track(self, sound_type):
        """
        :param sound_type: Vocal or Beat
        :return:
        """
        logger.info(f"play one track {sound_type}")
        if sound_type == "Vocal":
            self.__play_audio_one(self.y_vocal_shifted if self.autotune_flag else self.y_vocal, self.fs_vocal)
        else:
            self.__play_audio_one(self.y_beat, self.fs_beat)

    def play_audio_all(self):
        y1 = self.y_vocal_shifted if self.autotune_flag else self.y_vocal
        y2 = self.y_beat
        if y1 is None or y2 is None:
            if y2 is None:
                return self.__play_audio_one(y1, self.fs_vocal)
            else:
                return self.__play_audio_one(y2, self.fs_beat)
        length = max(len(y1), len(y2))  # å¯¹é½é•¿åº¦
        y1 = np.pad(y1, (0, length - len(y1)))
        y2 = np.pad(y2, (0, length - len(y2)))
        # æ··åˆï¼šç®€å•ç›¸åŠ å¹¶å½’ä¸€åŒ–
        mix = y1 + y2
        mix = mix / np.max(np.abs(mix))
        logger.debug(f"æ··åˆå¹¶æ’­æ”¾ Vocal å’Œ Beat éŸ³è½¨...")
        self.__play_audio_one(mix, self.fs_vocal)
        # sd.play(mix, self.fs_vocal)
        # sd.wait()

    def autotune_vocal(self, fmin=None, fmax=None):
        logger.info("autotuneåŒ–vocal")
        if self.y_vocal is None:
            return
        if not self.flush and os.path.exists(self.pickle_path_shifted_vocal):
            logger.info("ååºåˆ—åŒ–shifted vocal")
            with open(self.pickle_path_shifted_vocal, mode="rb") as f:
                self.y_vocal_shifted = pickle.load(f)
            return
        y = self.y_vocal
        if fmin is None and fmax is None:
            fmin, fmax = self.fmin, self.fmax
        # ä½¿ç”¨ PYIN åŸºé¢‘ä¼°è®¡
        # ä½¿ç”¨pYINç®—æ³•è¿›è¡ŒéŸ³é«˜æ£€æµ‹
        hop_length = self.frame_length // 4  # å¸§è·³è·ƒé•¿åº¦
        frame_length = self.frame_length
        freqs, voiced_flag, _ = librosa.pyin(y, fmin=fmin, fmax=fmax, sr=self.fs_vocal,
                                             hop_length=hop_length, frame_length=frame_length)
        n_frames = len(freqs)
        logger.info(f"freqsé•¿åº¦:{n_frames}")
        duration = n_frames * hop_length / self.fs_vocal
        logger.info(f"vocalæ€»æ—¶é•¿ï¼š{duration} s")

        key_frequencies = get_key_frequencies(self.key)
        print(f"è·å–ç›®æ ‡è°ƒå·çš„æ‰€æœ‰éŸ³é˜¶é¢‘ç‡{key_frequencies}")
        # å¯¹æ¯ä¸ªæ—¶é—´ç‚¹çš„é¢‘ç‡è¿›è¡Œæ ¡æ­£
        corrected_frequency = np.zeros_like(freqs)
        for idx, freq in enumerate(freqs):
            if np.isnan(freq) or freq < 100 or freq > 10000 or voiced_flag[idx] < 0.5:
                corrected_frequency[idx] = freq
                continue
            # å¯»æ‰¾æœ€æ¥è¿‘çš„è°ƒå†…éŸ³é˜¶é¢‘ç‡
            closest_key_freq = min(key_frequencies, key=lambda x: abs(np.log2(x / freq)))
            # closest_key_freq = key_frequencies[key_frequencies.index(closest_key_freq) + (1 if key_frequencies.index(closest_key_freq)%2 else -1)]
            if abs(closest_key_freq-freq) < 0:
                corrected_frequency[idx] = freq
            else:
                corrected_frequency[idx] = closest_key_freq
                logger.info(f"çŸ«æ­£é¢‘ç‡ï¼š{freq} hz to {corrected_frequency[idx]} hz")
            # corrected_frequency[idx] = 184
        # å°†é¢‘ç‡å˜æˆæ³¢å½¢, æœ€æ ¸å¿ƒçš„ä¸€è¡Œä»£ç ğŸ¤£
        self.y_vocal_shifted = psola.vocode(self.y_vocal, sample_rate=self.fs_vocal,
                                            target_pitch=corrected_frequency, fmin=fmin, fmax=fmax)
        # åºåˆ—åŒ–
        if self.save_ans:
            logger.info("åºåˆ—åŒ–shifted vocal")
            with open(self.pickle_path_shifted_vocal, mode="wb") as f:
                pickle.dump(self.y_vocal_shifted, f)

    def main_work(self):
        self.read_audio()
        self.autotune_vocal()
        self.play_audio_all()


class RunThread(QThread):
    finished = Signal(tuple)

    def __init__(self, autotune=None):
        super().__init__()
        if autotune is None:
            self.autotune = Autotune(
                input_beat="",
                input_audio_vocal="",
                key="C:maj",
                flush=True,
            )
        else:
            self.autotune = autotune

    def run(self):
        self.autotune.autotune_vocal()
        self.finished.emit((self.autotune,))


# if __name__ == "__main__":
#     tangyijun_autotune = TangYijunAutotune(
#         input_audio_vocal="çœ‹æœˆäº®çˆ¬ä¸Šæ¥vocal.mp3",
#         input_beat="çœ‹æœˆäº®çˆ¬ä¸Šæ¥ä¼´å¥.mp3",
#         key="F#:maj",
#         flush=False
#     )
#     tangyijun_autotune.main_work()


class AudioPlayerUI(QWidget):
    def __init__(self):
        super().__init__()
        self.key = "C"
        self.key_type = "maj"
        self.setWindowTitle("å”ä¹‰å†›çš„autotune")
        self.setMinimumSize(400, 200)
        layout = QVBoxLayout()

        # åˆ›å»ºä¸¤ä¸ªéŸ³é¢‘ç»„
        self.player_widgets = []
        temp = {
            0: "Vocal",
            1: "Beat"
        }
        self.autotune = Autotune(
            input_beat="",
            input_audio_vocal="",
            key="C:maj",
            flush=True,
        )
        self.thread = None
        # self.run_thread = RunThread()
        # éŸ³é¢‘keyä¿¡æ¯
        group_layout0 = QHBoxLayout()
        # ç¬¬ä¸€ä¸ªä¸‹æ‹‰
        self.label1 = QLabel("è°ƒï¼š")
        self.combo1 = QComboBox()
        self.combo1.addItems(["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B",])
        self.combo1.currentTextChanged.connect(self.on_select1)

        # ç¬¬äºŒä¸ªä¸‹æ‹‰
        self.label2 = QLabel("è°ƒå¼ï¼š")
        self.combo2 = QComboBox()
        self.combo2.addItems(["maj", "min"])
        self.combo2.currentTextChanged.connect(self.on_select2)

        group_layout0.addWidget(self.label1)
        group_layout0.addWidget(self.combo1)
        group_layout0.addWidget(self.label2)
        group_layout0.addWidget(self.combo2)
        layout.addLayout(group_layout0)
        layout.addStretch()
        for i in range(2):
            group = QGroupBox(f"éŸ³é¢‘é€šé“ {i+1}_{temp[i]}")
            group_layout = QHBoxLayout()

            label = QLabel("æœªé€‰æ‹©éŸ³é¢‘")
            btn_select = QPushButton("é€‰æ‹©éŸ³é¢‘")
            btn_play = QPushButton("æ’­æ”¾")
            btn_remove = QPushButton("Remove")

            # ç»‘å®šä¿¡å·
            btn_select.clicked.connect(lambda _, ii=i, lb=label: self.select_file(sound_type=temp[ii], label=lb))
            btn_play.clicked.connect(lambda _, ii=i: self.autotune.play_one_track(sound_type=temp[ii]))
            btn_remove.clicked.connect(lambda _, ii=i, lb=label: self.remove_sound_file(sound_type=temp[ii], label=lb))

            group_layout.addWidget(label)
            group_layout.addWidget(btn_select)
            group_layout.addWidget(btn_play)
            group_layout.addWidget(btn_remove)
            group.setLayout(group_layout)
            layout.addWidget(group)
        # æ·»åŠ æ’­æ”¾å…¨éƒ¨æŒ‰é’®
        final_h_layout = QHBoxLayout()
        btn_play_all = QPushButton("æ’­æ”¾å…¨éƒ¨")
        btn_stop_play_all = QPushButton("åœæ­¢æ’­æ”¾")
        autotune_on = QRadioButton("Vocal autotuneæ•ˆæœ")

        # ç»‘å®šä¿¡å·
        btn_play_all.clicked.connect(lambda _: self.autotune.play_audio_all())
        btn_stop_play_all.clicked.connect(lambda _: self.autotune.stop_play())
        autotune_on.toggled.connect(self.on_toggled)
        final_h_layout.addWidget(btn_play_all)
        final_h_layout.addWidget(btn_stop_play_all)
        final_h_layout.addWidget(autotune_on)
        layout.addLayout(final_h_layout)
        layout.addStretch()
        self.setLayout(layout)

    def on_toggled(self, checked: bool):
        # checked=True æ—¶ä¸ºâ€œå¼€â€ï¼ŒFalse æ—¶ä¸ºâ€œå…³â€
        self.autotune.autotune_flag = True if checked else False
        logger.info(f"change autotune flag {self.autotune.autotune_flag}")

    def __update_key(self):
        self.autotune.key = f"{self.key}:{self.key_type}"
        self.__update_autotune()

    def __update_autotune_finish(self, result):
        self.autotune = result[0]
        self.a.close()
        self.a.destroy()
        pass
    def __update_autotune(self):
        self.thread = RunThread(self.autotune)
        self.a = QDialog(self)
        self.thread.finished.connect(self.__update_autotune_finish)
        self.a.setWindowTitle("è®¡ç®—ä¸­ï¼Œè¯·ç¨ç­‰...")
        self.a.setModal(True)
        self.a.setFixedSize(200, 100)
        # self.a.resize(QSize(200, 100))
        # self.setWindow
        self.a.setWindowModality(Qt.ApplicationModal)  # åº”ç”¨çº§æ¨¡æ€
        # self.a.setWindowFlags(self.a.windowFlags() & ~Qt.WindowType.WindowCloseButtonHint)
        self.thread.start()

        self.a.exec()
        # self.a.show()

    def on_select1(self, text):
        print(f"ç¬¬ä¸€ä¸ªä¸‹æ‹‰é€‰æ‹©ï¼š{text}")
        self.key = text
        self.__update_key()

    def on_select2(self, text):
        print(f"ç¬¬äºŒä¸ªä¸‹æ‹‰é€‰æ‹©ï¼š{text}")
        self.key_type = text
        self.__update_key()

    def select_file(self, sound_type, label):
        file_path, _ = QFileDialog.getOpenFileName(self, "é€‰æ‹©éŸ³é¢‘æ–‡ä»¶", "", "éŸ³é¢‘æ–‡ä»¶ (*.mp3 *.wav *.ogg)")
        if file_path:
            url = QUrl.fromLocalFile(file_path)
            logger.info("é€‰æ‹©æ–‡ä»¶ï¼š" + url.path() + " type: " + sound_type)
            label.setText(file_path.split('/')[-1])
            if sound_type == "Vocal":
                logger.info("è½½å…¥Vocal")
                self.autotune.input_audio_vocal = url.path()
                self.autotune.read_audio(sound_type=sound_type)
                # self.autotune.autotune_vocal()
                self.__update_autotune()
            else:
                logger.info("è½½å…¥beat")
                self.autotune.input_beat = url.path()
                self.autotune.read_audio(sound_type=sound_type)

    def remove_sound_file(self, sound_type, label):
        logger.info(f"remove sound file:{sound_type}")
        if sound_type == "Vocal":
            self.autotune.fs_vocal = None
            self.autotune.y_vocal = None
            self.autotune.input_audio_vocal = None
            self.autotune.y_vocal_shifted = None
        else:
            self.autotune.fs_beat = None
            self.autotune.y_beat = None
            self.autotune.input_beat = None
        label.setText("æœªé€‰æ‹©éŸ³é¢‘")


if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = AudioPlayerUI()
    window.show()
    sys.exit(app.exec())
